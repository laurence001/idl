## Information Disorder Level (IDL) index

Generative AI, through large language models, has become a cheap and quick method to generate misleading or fake stories. However, producing false or inaccurate results is not always intentional, as machine-generated contents are subject to “artificial hallucinations”. Therefore, defining the (non)human nature of the author seems pointless, especially since detection methods still remain limited. A different perspective is grounded in the tradition of human judgement methods that have been developed in natural language processing (NLP) to assess the qualitative characteristics of machine-generated content. It consists of evaluating the ability of the system to stick to the facts through an adapted language-independent metric. This tool helps to understand the limits of generative AI and fosters a reflection on what factuality is.

Dierickx, L., Lindén, CG., Opdahl, A.L. (2023). The Information Disorder Level (IDL) Index: A Human-Based Metric to Assess the Factuality of Machine-Generated Content. In: Ceolin, D., Caselli, T., Tulin, M. (eds) Disinformation in Open Online Media. MISDOOM 2023. Lecture Notes in Computer Science, vol 14397. Springer, Cham. https://doi.org/10.1007/978-3-031-47896-3_5

URL: https://laurence001.github.io/idl/ (PROTOTYPE)

PRODUCTION FOR TRAINING DATA : https://idlindex.net

DEMO: https://youtu.be/KME3bnt9OPY
